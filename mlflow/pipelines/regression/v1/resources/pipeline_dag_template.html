<!DOCTYPE html>
<html lang="en">
  <body>
    <style>
      .mermaidTooltip{
        display: none;
      }
      .wrapper {
        display: flex;
      }
      .mermaid {
        width: 60%;
      }
      #editor {
        font-size: 13px;
        width: 40%;
      }
      font {
        font-size: 24px;
        padding: 24px;
      }
    </style>

    <div class="wrapper">
      <div class="mermaid">
          flowchart TB
          pipeline(pipeline.yaml)

          ingestUserCode([steps/ingest.py]) --> ingestMLPStep[["<font>ingest</font>"]]
          ingestMLPStep --> dataParquet[(ingested_data)]

          data[(ingested_data)] --> splitStep[["<font>split</font>"]]
          splitStep --> splitData1[(training_data, <br> validation_data)]
          splitStep --> splitData2[(test_data)]
          splitData1 --> transformMLPStep[["<font>transform</font>"]]

          transformUserCode([steps/transform.py]) --> transformMLPStep
          transformMLPStep --> transformedParquet[(transformed_training_data, <br/> transformed_validation_data)]
          transformedParquet --> trainMLPStep[["<font>train</font>"]]

          trainUserCode([steps/train.py]) --> trainMLPStep
          trainMLPStep --> run{{run}}
          trainMLPStep --> model{{model}}

          model --> evaluateMLPStep[["<font>evaluate</font>"]]
          evaluateUserCode([steps/evaluate.py]) --> evaluateMLPStep
          splitData2 --> evaluateMLPStep

          click ingestMLPStep noOp "  # Dataset locations on the local filesystem are supported, as well as any remote
  # locations resolvable by MLflow, such as those listed in
  # https://mlflow.org/docs/latest/tracking.html#artifact-stores
  location: ./datasets/autos.parquet
  # The `spark_sql` and `delta` formats are also natively supported for use with Spark
  format: parquet"
          click ingestUserCode noOp "def load_file_as_dataframe(&#013; file_path: str, &#013; file_format: str&#013;) -> Pandas.parquet"
          click splitStep noOp "  # Should be an array where each value corresponds to [train, validation, test] dataset split.
  # Each value should be between 0.0 and 1.0 which represent the respective proportion of the dataset to include.
  split_ratio: [0.75, 0.125, 0.125]"
          click transformMLPStep noOp "# Please override the steps/transform.py for customization"
          click transformUserCode noOp "def transform() -> transformer"
          click trainMLPStep noOp "# Please override the steps/train.py for customization"
          click trainUserCode noOp "def train() -> model"
          click evaluateMLPStep noOp "# Please override the steps/evaluate.py for customization"
          click evaluateUserCode noOp "def custom_metric_fns() -> List[Callable]"

          click pipeline renderMoreInformation "{{pipeline_yaml}}"
          click dataParquet noOp "data ingested from source"
          click data noOp "data ingested from source"
          click splitData1 noOp "Outputs splits for training and validation"
          click splitData2 noOp "Output split for evaluating the model"
          click transformedParquet noOp "Transformed output of training and validation needed for training"
          click run noOp "Output run which is tracked in MLFlow"
          click model noOp "Output model form training"

      </div>
      <div id="editor"></div>
    </div>

    <script src="http://requirejs.org/docs/release/2.1.5/comments/require.js"></script>
    <script type="text/javascript">
      require.config({
        paths: {
            "mermaid": "https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min",
            "ace": "https://cdnjs.cloudflare.com/ajax/libs/ace/1.5.1/",
            "python": "https://cdnjs.cloudflare.com/ajax/libs/ace/1.5.1/mode-python.min",
            "monokai": "https://cdnjs.cloudflare.com/ajax/libs/ace/1.5.1/theme-monokai.min"
        },
      });
      require(["mermaid"],
        function (mermaid) {
          const config = {
            startOnLoad:true,
            securityLevel:'loose',
            theme: (window.matchMedia && window.matchMedia("(prefers-color-scheme: dark)").matches) ? "dark" : "default",
            flowchart:{
                useMaxWidth:true,
                htmlLabels:true,
            }
          };
          mermaid.initialize(config);
          mermaid.init();
          const nodes = document.querySelectorAll(".node");
          [...nodes].forEach((node) => {
            const nodeTitle = node.getAttribute('title');
            if(nodeTitle) {
              const nodeLabel = node.querySelector(".nodeLabel");
              nodeLabel.setAttribute("title", nodeTitle)
            }
          })

          window.editor = null;
        }
      );

      var noOp = function() {}
      var renderMoreInformation = function(nodeId) {
        const allNodes = document.querySelector('.nodes').querySelectorAll('[id^="flowchart-"]');
        [...allNodes].forEach(nodes => {
          const rect = nodes.firstChild
          if (rect) {
            rect.style.stroke = "";
            rect.style.strokeWidth = "";
            rect.style.color = "";
            rect.style.strokeDasharray = "";
          }
        });

        regex = `[id^="flowchart-${nodeId}-"]`
        const node = document.querySelector(regex);
        const title = node.getAttribute('title');

        const rect = node.firstChild;
        rect.style.stroke = "#f66";
        rect.style.strokeWidth = "2px";
        rect.style.color = "#fff";
        rect.style.strokeDasharray = "5 5";

        require(["ace/ace", "python", "monokai"],
          function (ace) {
            if (!window.editor) {
              const editor = ace.edit("editor");
              editor.setTheme("ace/theme/monokai");
              editor.session.setMode("ace/mode/python");
              editor.setReadOnly(true);
              window.editor = editor;
            }
            window.editor.setValue(title)
          }
        );
      }
    </script>

  </body>
</html>
